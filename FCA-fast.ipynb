{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Julia-is-Fast Benchmark Fun: `sum`\n",
    "\n",
    "In this notebook we are going to compare performance of a very simple function across several different languages: The `sum`. This function computes\n",
    " \n",
    "$$\\text{sum}(a) = \\sum_{i=1}^n a_i$$\n",
    "\n",
    "where $n$ is the length of `a`.\n",
    "Let's get a vector of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rand(10^7) # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect to see 0.5*10^7, since each element has an expected value of 0.5.\n",
    "\n",
    "## Benchmarks in different languages\n",
    "\n",
    "We will use BenchmarkTools.jl for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `C` is what you have to beat\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "One can compile C code in Julia. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "using Libdl\n",
    "\n",
    "open(`gcc  -fPIC -O3 -ffast-math -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)\n",
    "\n",
    "c_sum(a)\n",
    "\n",
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb\n",
    "\n",
    "c_bench = @benchmark c_sum($a)\n",
    "\n",
    "println(\"C: Fastest time was $(minimum(c_bench.times) / 1e6) msec\")\n",
    "\n",
    "d = Dict()  # a \"dictionary\", i.e. an associative array\n",
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the BenchmarkTools library takes many sample runs to account for machine noise in the benchmark. We can look at the distribution of times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "t = c_bench.times / 1e6 # times in milliseconds\n",
    "using Statistics\n",
    "m, σ = minimum(t), std(t)\n",
    "\n",
    "histogram(t, bins=500,\n",
    "    xlim=(m - 0.01, m + σ),\n",
    "    xlabel=\"milliseconds\", ylabel=\"count\", label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: python's built-in `sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "# Call a low-level PyCall function to get a Python list, because\n",
    "# by default PyCall will convert to a NumPy array instead (we benchmark NumPy below):\n",
    "\n",
    "apy_list = PyCall.array2py(a, 1, 1)\n",
    "\n",
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")\n",
    "\n",
    "pysum(a)\n",
    "\n",
    "pysum(a) ≈ sum(a)\n",
    "\n",
    "py_list_bench = @benchmark $pysum($apy_list)\n",
    "\n",
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: python's numpy `sum`\n",
    "\n",
    "Takes advantage of hardware \"SIMD\", but only works when it works.\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be used within Julia as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Conda \n",
    "\n",
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "apy_numpy = PyObject(a) # converts to a numpy array by default\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($apy_numpy)\n",
    "\n",
    "numpy_sum(apy_list) # python thing\n",
    "\n",
    "numpy_sum(apy_list) ≈ sum(a)\n",
    "\n",
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: python hand-written\n",
    " \n",
    "We could try and see how our hand-written implementation performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "def py_sum(a):\n",
    "    s = 0.0\n",
    "    for x in a:\n",
    "        s = s + x\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\"\n",
    "\n",
    "py_hand = @benchmark $sum_py($apy_list)\n",
    "\n",
    "sum_py(apy_list)\n",
    "\n",
    "sum_py(apy_list) ≈ sum(a)\n",
    "\n",
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## julia built-in\n",
    "\n",
    "`julia`s library is written entirely in julia! No `C` at all! you can easily look at the code by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_bench = @benchmark sum($a)\n",
    "\n",
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## julia hand-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum(A)   \n",
    "    s = 0.0  # s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "j_bench_hand = @benchmark mysum($a)\n",
    "\n",
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `R` built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "r_bench = @benchmark R\"sum($a)\"\n",
    "d[\"R built-in\"] = minimum(r_bench.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, value) in sort(collect(d), by=x->x[2])\n",
    "    println(rpad(key, 20, \".\"), lpad(round(value,digits= 2), 10, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take aways (on my computer!):\n",
    "\n",
    "1. `C` is fastest\n",
    "1. built-in julia checks out very close to `C`, and ex-equo with the numpy\n",
    "1. Hand written julia gets compiled to very efficient machine code in this example.\n",
    "1. Python and R built-in sums are roughly 10 times slower than `C`, `julia` and `numpy`\n",
    "1. Hand writing python code without any optimizations performs poorly in this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
